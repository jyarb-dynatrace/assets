{"version":1,"defaultTimeframe":{"from":"now-2h","to":"now"},"sections":[{"id":"0","type":"markdown","markdown":"\nUse OpenPipeline to transform data on ingest before it is stored in Grail.\n\n*Goal:* We want to use a Segment to filter data based on team ownership.  Ownership metadata does not exist on data stored in Grail.  Use OpenPipeline to identify ownership metadata and add it as additional attribute(s).\n\n* Logs Pipeline\n* Metrics Pipeline"},{"id":"1","type":"markdown","markdown":"\nUse OpenPipeline to transform log data on ingest prior to being stored in Grail.\n\n### Query Existing Log Data\n\nUse the `Logs` App to explore the existing log data for the IDP and the deployed applications.  Note that Dynatrace is deployed with `Application Monitoring` Dynakube and Kubernetes Observability.  Logs are collected using an OpenTelemetry Collector that ships the logs to Dynatrace.\n\n![Logs App](https://university.dynatrace.com/assets/50457/04_01_logs_app_viewer.png)\n\nFrom the Logs App, try to locate logs that are relevant to a specific application team (i.e. team01 or team02).\n\nImport the [IDP OpenPipeline Notebook](https://github.com/dynatrace-wwse/enablement-openpipeline-segments-iam/blob/main/lab-guide/assets/dynatrace/IDP_%20OpenPipeline_Notebook.json) Notebook into the Dynatrace environment.\n\n![Existing Logs](https://university.dynatrace.com/assets/50457/04_01_notebook_query_existing_logs.png)\n\nExecute the first DQL query, which retrieves the logs from the `SimpleNodeService` pods.  Take notice of the `dt.security_context`, `idp_project`, `idp_team`, and `idp_stage` attributes.  We want to use OpenPipeline to modify/add these fields to the log records.\n\nDQL:\n```sql\nfetch logs\n| filter matchesPhrase(k8s.pod.name,\"simplenodeservice-\")\n| sort timestamp desc\n| fields timestamp, dt.security_context, k8s.cluster.name, k8s.namespace.name, k8s.container.name, idp_team, idp_project, idp_stage\n```\n\n### Create Pipeline\n\nFrom the Dynatrace environment, locate and launch the `OpenPipeline` App.  Select the `Logs` tab on the left.\n\n![OpenPipeline App](https://university.dynatrace.com/assets/50457/04_01_openpipeline_logs.png)\n\nClick on the `Pipelines` tab.\n\n![New Pipeline](https://university.dynatrace.com/assets/50457/04_01_openpipeline_new_pipeline.png)\n\nClick on `+ Pipeline` to create a new pipeline.\n\n![Name Pipeline](https://university.dynatrace.com/assets/50457/04_01_pipeline_identify_nodejs.png)\n\nRename the pipeline to `idp-project-logs`.  Select the `Processing` tab.  Add a new processor and choose `Add fields`.\n\nName:\n```text\nIdentify NodeJS\n```\n\nMatching Condition:\n```text\nmatchesPhrase(k8s.pod.name,\"simplenodeservice-\")\n```\n\nField Name:\n```text\nprocess.technology\n```\n\nField Value:\n```text\nnodejs\n```\n\n![NodeJS Tech Bundle](https://university.dynatrace.com/assets/50457/04_01_pipeline_nodejs_tech_bundle.png)\n\nAdd a new processor and choose `Technology Bundle`.  Choose the `NodeJS` bundle in the Applications category.\n\nThis technology bundle will attempt to parse logs for patterns commonly used by NodeJS frameworks.\n\n![Parse Namespace](https://university.dynatrace.com/assets/50457/04_01_pipeline_parse_namespace.png)\n\nAdd a new processor and choose `DQL`.\n\nName:\n```text\nParse Namespace\n```\n\nMatching Condition:\n```text\nisNotNull(k8s.namespace.name)\n```\n\nDQL:\n```text\nparse k8s.namespace.name, \"LD:idp_project '-' LD:idp_team '-' LD:idp_stage\"\n```\n\n![Parse Cluster](https://university.dynatrace.com/assets/50457/04_01_pipeline_parse_cluster.png)\n\nAdd a new processor and choose `DQL`.\n\nName:\n```text\nParse Cluster\n```\n\nMatching Condition:\n```text\nisNotNull(k8s.cluster.name)\n```\n\nDQL:\n```text\nfieldsAdd idp_cluster = k8s.cluster.name\n```\n\n![Security Context](https://university.dynatrace.com/assets/50457/04_01_pipeline_add_security_context.png)\n\nAdd a new processor and choose `DQL`.\n\nName:\n```text\nSecurity Context\n```\n\nMatching Condition:\n```text\nisNotNull(idp_cluster) and isNotNull(idp_team)\n```\n\nDQL:\n```text\nfieldsAdd idp_security_context = concat(\"idp_\",idp_team,\"_\",idp_cluster)\n```\n\n![Set Security Context](https://university.dynatrace.com/assets/50457/04_01_pipeline_set_security_context.png)\n\nSelect the `Permission` tab.  Add a new processor and choose `Set security context`.\n\nName:\n```text\nIDP Security Context\n```\n\nMatching Condition:\n```text\nisNotNull(idp_security_context)\n```\n\nField Name\n```text\nidp_security_context\n```\n\nClick on `Save` to save the pipeline configuration.\n\n### Create Dynamic Route\n\nFrom the OpenPipeline Logs configuration page, click on `Dynamic Routing`.\n\n![Dynamic Routes](https://university.dynatrace.com/assets/50457/04_01_pipeline_routes_new_route.png)\n\nClick on `+ Dynamic Route` to create a new route for the pipeline.\n\n![New Route](https://university.dynatrace.com/assets/50457/04_01_pipeline_set_dynamic_route.png)\n\nSet the dynamic route properties:\n\nName:\n```text\nidp-project-logs\n```\n\nMatching Condition:\n```text\nk8s.cluster.name == \"platform-engineering-demo\" and isNotNull(k8s.namespace.name)\n```\n\nPipeline:\n```text\nidp-project-logs\n```\n\nClick `Save` to save the dynamic route configuration.  This change is not retroactive.  New logs matching the condition will be routed through the new pipeline.\n\n### Query New Log Data\n\nThe change will likely take a few minutes to complete.  After some time, return to the `IDP OpenPipeline` Notebook.\n\n![Query New Logs](https://university.dynatrace.com/assets/50457/04_01_notebook_query_new_logs.png)\n\nRe-run the first query.  Continue to run the query until the `idp_*` fields no longer return `null`.  The new fields can be used to filter log data at query time.  Additionally, the new value of `dt.security_context` can be used to configure record-level permissions with IAM Policies.\n\nDQL:\n```sql\nfetch logs\n| filter matchesPhrase(k8s.pod.name,\"simplenodeservice-\")\n| sort timestamp desc\n| fields timestamp, dt.security_context, k8s.cluster.name, k8s.namespace.name, k8s.container.name, idp_team, idp_project, idp_stage\n```\n\n![Summarize New Logs](https://university.dynatrace.com/assets/50457/04_01_notebook_summarize_new_logs.png)\n\nExecute the second query and summarize the new log data.  It is now easy to identify logs based on the `idp_team`, `idp_project`, and `idp_stage` details.\n\nDQL:\n```sql\nfetch logs\n| filter matchesPhrase(k8s.pod.name,\"simplenodeservice-\")\n| summarize logs = count(), by: {dt.security_context, k8s.cluster.name, k8s.namespace.name, idp_team, idp_project, idp_stage}\n```\n\n"},{"id":"2","type":"markdown","markdown":"\nUse OpenPipeline to transform metric data on ingest prior to being stored in Grail.\n\n### Create Pipeline\n\nFrom the Dynatrace environment, locate and launch the `OpenPipeline` App.  Select the `Metrics` tab on the left.\n\n![OpenPipeline App](https://university.dynatrace.com/assets/50457/04_02_openpipeline_metrics.png)\n\nClick on the `Pipelines` tab.\n\n![New Pipeline](https://university.dynatrace.com/assets/50457/04_02_openpipeline_new_pipeline.png)\n\nClick on `+ Pipeline` to create a new pipeline.\n\n![Name Pipeline](https://university.dynatrace.com/assets/50457/04_02_pipeline_parse_namespace.png)\n\nRename the pipeline to `idp-project-metrics`.  Select the `Processing` tab.  Add a new processor and choose `DQL`.\n\nName:\n```text\nParse Namespace\n```\n\nMatching Condition:\n```text\nisNotNull(k8s.namespace.name) and matchesPhrase(k8s.namespace.name,\"simplenodeservice\")\n```\n\nDQL:\n```text\nparse k8s.namespace.name, \"LD:idp_project '-' LD:idp_team '-' LD:idp_stage\"\n```\n\n![Add Project](https://university.dynatrace.com/assets/50457/04_02_pipeline_idp_project.png)\n\nAdd a new processor and choose `DQL`.\n\nName:\n```text\nIDP Project\n```\n\nMatching Condition:\n```text\nisNotNull(idp_team) and isNotNull(idp_stage) and matchesPhrase(k8s.namespace.name,\"simplenodeservice\")\n```\n\nDQL:\n```text\nfieldsAdd idp_project = \"simplenodeservice\"\n```\n\n![Parse Cluster](https://university.dynatrace.com/assets/50457/04_02_pipeline_parse_cluster.png)\n\nAdd a new processor and choose `DQL`.\n\nName:\n```text\nParse Cluster\n```\n\nMatching Condition:\n```text\nisNotNull(k8s.cluster.name)\n```\n\nDQL:\n```text\nfieldsAdd idp_cluster = k8s.cluster.name\n```\n\n![Security Context](https://university.dynatrace.com/assets/50457/04_02_pipeline_add_security_context.png)\n\nAdd a new processor and choose `DQL`.\n\nName:\n```text\nSecurity Context\n```\n\nMatching Condition:\n```text\nisNotNull(idp_team) and isNotNull(idp_cluster)\n```\n\nDQL:\n```text\nfieldsAdd idp_security_context = concat(\"idp_\",idp_team,\"_\",idp_cluster)\n```\n\n![Set Security Context](https://university.dynatrace.com/assets/50457/04_02_pipeline_set_security_context.png)\n\nSelect the `Permission` tab.  Add a new processor and choose `Set security context`.\n\nName:\n```text\nIDP Security Context\n```\n\nMatching Condition:\n```text\nisNotNull(idp_security_context)\n```\n\nField Name\n```text\nidp_security_context\n```\n\nClick on `Save` to save the pipeline configuration.\n\n### Create Dynamic Route\n\nFrom the OpenPipeline Metrics configuration page, click on `Dynamic Routing`.\n\n![Dynamic Routes](https://university.dynatrace.com/assets/50457/04_02_pipeline_routes_new_route.png)\n\nClick on `+ Dynamic Route` to create a new route for the pipeline.\n\n![New Route](https://university.dynatrace.com/assets/50457/04_02_pipeline_set_dynamic_route.png)\n\nSet the dynamic route properties:\n\nName:\n```text\nidp-project-metrics\n```\n\nMatching Condition:\n```text\nisNotNull(k8s.namespace.name) and matchesPhrase(k8s.namespace.name,\"simplenodeservice\")\n```\n\nPipeline:\n```text\nidp-project-metrics\n```\n\nClick `Save` to save the dynamic route configuration.  This change is not retroactive.  New metric data points matching the condition will be routed through the new pipeline.\n\n### Query New Metric Data\n\nThe change will likely take a few minutes to complete.  After some time, return to the `IDP OpenPipeline` Notebook.\n\n![Query Container CPU](https://university.dynatrace.com/assets/50457/04_02_notebook_query_cpu.png)\n\nLocate the first explore metrics section and query the metric `dt.kubernetes.container.cpu_usage`.\n\nLeverage the new OpenPipeline configuration and filter the metric on `idp_project=simplenodeservice` and `idp_team=team01`.\n\nSplit the metric by `k8s.pod.name`.  The chart now shows container CPU usage per pod, only for pods that belong to idp team `team01`.\n\n![Query Service Throughput](https://university.dynatrace.com/assets/50457/04_02_notebook_query_service.png)\n\nLocate the second explore metrics section and query the metric `dt.service.request.count`.\n\nLeverage the new OpenPipeline configuration and filter the metric on `idp_team=team02`.\n\nSplit the metric by `idp_stage` and `dt.entity.service`.  The chart now shows service request count per service, only for services that belong to idp team `team02`."}]}